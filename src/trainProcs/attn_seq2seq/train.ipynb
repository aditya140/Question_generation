{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from dataloader import SimpleDataloader\n",
    "from params import ATTN_SEQ2SEQ_PARAMS\n",
    "from models.attn_seq2seq import AttnSeq2seq, count_parameters, Encoder, Decoder\n",
    "from utils import (\n",
    "    save_model,\n",
    "    get_torch_device,\n",
    "    epoch_time,\n",
    "    arg_copy,\n",
    "    save_to_artifact,\n",
    "    save_test_df,\n",
    "    save_metrics,\n",
    ")\n",
    "from test_metrics.test_model import Model_tester\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import argparse\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = ATTN_SEQ2SEQ_PARAMS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading Form Cache\n"
    }
   ],
   "source": [
    "device = get_torch_device()\n",
    "\n",
    "\n",
    "data = SimpleDataloader(**vars(hp))\n",
    "train_dataloader = data.get_train_dataloader()\n",
    "val_dataloader = data.get_val_dataloader()\n",
    "test_dataloader = data.get_test_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The model has 166,763,401 trainable parameters\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AttnSeq2seq(\n  (encoder): Encoder(\n    (embedding): Embedding(45000, 300)\n    (rnn): LSTM(300, 600, num_layers=2, dropout=0.3, bidirectional=True)\n    (dropout): Dropout(p=0.3, inplace=False)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(45000, 300)\n    (rnn): LSTM(300, 1200, num_layers=2, dropout=0.3)\n    (attention): Attention()\n    (fc): Linear(in_features=2400, out_features=45000, bias=True)\n    (dropout): Dropout(p=0.3, inplace=False)\n  )\n)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "\n",
    "model = AttnSeq2seq(**vars(hp))\n",
    "model.init_weights()\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "it=iter(val_dataloader)\n",
    "src,trg,src_len=next(it)\n",
    "src = src.to(device) \n",
    "trg = trg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(src, trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting Loss:  10.714410691891077\n----------\nEpoch : 0\n\tTraining for 953 iter\n\t\tIter:0----loss:10.714405059814453\n\t\tIter:100----loss:6.7219462394714355\n\t\tIter:200----loss:6.329308986663818\n\t\tIter:300----loss:6.331459045410156\n\t\tIter:400----loss:5.928847312927246\n\t\tIter:500----loss:5.9180707931518555\n\t\tIter:600----loss:5.746861934661865\n\t\tIter:700----loss:5.6512770652771\n\t\tIter:800----loss:5.882458209991455\n\t\tIter:900----loss:5.733606815338135\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'version' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6c1dd306802f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;34m\"test_df\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;34m\"params\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;34m\"version\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         }\n\u001b[1;32m    111\u001b[0m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"seq2seq.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mto_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'version' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Loss Function and optimizers\n",
    "\"\"\"\n",
    "CCE = lambda x, y: F.cross_entropy(x, y, ignore_index=0)\n",
    "if hp.optim == \"adam\":\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=hp.lr)\n",
    "if hp.optim == \"SGD\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=hp.lr)\n",
    "\n",
    "\"\"\"\n",
    "Scheduler\n",
    "\"\"\"\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    verbose=False,\n",
    "    threshold=0.0001,\n",
    "    threshold_mode=\"rel\",\n",
    "    cooldown=0,\n",
    "    min_lr=0,\n",
    "    eps=1e-08,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Train Function\n",
    "\"\"\"\n",
    "\n",
    "def train(model, dataloader, optimizer, loss_fn, device, print_freq=100):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    print(f\"\\tTraining for {len(dataloader)} iter\")\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        src, trg, src_len = batch\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        pred = model(src, trg)\n",
    "        pred = pred.permute(1, 2, 0)\n",
    "        loss = loss_fn(pred, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        if idx % print_freq == 0:\n",
    "            print(f\"\\t\\tIter:{idx}\", f\"loss:{loss.item()}\", sep=\"----\")\n",
    "    return losses\n",
    "\n",
    "\"\"\"\n",
    "Evaluate Function\n",
    "\"\"\"\n",
    "\n",
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        src, trg, src_len = batch\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(src, trg)\n",
    "        pred = pred.permute(1, 2, 0)\n",
    "        loss = loss_fn(pred, trg)\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses)\n",
    "\n",
    "\"\"\"\n",
    "Generate Test Dataframe\n",
    "\"\"\"\n",
    "\n",
    "def create_test_df(dataloader):\n",
    "    data = []\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        inp, opt = batch\n",
    "        for i in range(len(inp)):\n",
    "            data_dict = {\"input\": inp[i], \"output\": opt[i]}\n",
    "            data.append(data_dict)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def test_model(model, inpLang, optLang, test_df):\n",
    "    tester = Model_tester(model, inpLang, optLang, max_len=40)\n",
    "    tester.set_inference_mode(\"greedy\")\n",
    "    return tester.generate_metrics(test_df)\n",
    "\n",
    "\"\"\"\n",
    "Main Loop\n",
    "\"\"\"\n",
    "test_df = create_test_df(test_dataloader)\n",
    "best_model_loss = float(\"inf\")\n",
    "val_loss = evaluate(model, val_dataloader, CCE, device)\n",
    "print(\"Starting Loss: \", val_loss)\n",
    "for ep in range(hp.epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"Epoch : {ep}\")\n",
    "    st_time = time.time()\n",
    "    train_loss = train(model, train_dataloader, optimizer, CCE, device)\n",
    "    val_loss = evaluate(model, val_dataloader, CCE, device)\n",
    "    scheduler.step(val_loss)\n",
    "    if val_loss < best_model_loss:\n",
    "        to_save = {\n",
    "            \"model\": model,\n",
    "            \"inpLang\": data.inpLang,\n",
    "            \"optLang\": data.optLang,\n",
    "            \"test_df\": test_df,\n",
    "            \"params\": vars(hp),\n",
    "            \"version\": version,\n",
    "        }\n",
    "        save_model(path=hp.save_path, name=\"seq2seq.pt\", **to_save)\n",
    "        best_model_loss = val_loss\n",
    "    e_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(st_time, e_time)\n",
    "    print(\n",
    "        f\"\\tTraining Loss : {np.mean(train_loss)}\",\n",
    "        f\"Train Perplexity : {math.exp(np.mean(train_loss))}\",\n",
    "        sep=\"\\t|\\t\",\n",
    "    )\n",
    "    print(\n",
    "        f\"\\tVal Loss      : {val_loss}\",\n",
    "        f\"Val Perplexity : {math.exp(val_loss)}\",\n",
    "        sep=\"\\t|\\t\",\n",
    "    )\n",
    "    print(f\"\\tTime per epoch: {epoch_mins}m {epoch_secs}s\")\n",
    "print(\"Generating Test Metrics\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, metrics = test_model(model, data.inpLang, data.optLang, test_df)\n",
    "save_test_df(df, \"seq2seq\", version)\n",
    "save_metrics(metrics, \"seq2seq\", version)\n",
    "print(metrics)\n",
    "if hp.to_artifact:\n",
    "    save_to_artifact(\"seq2seq\", version)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1593994709740",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}